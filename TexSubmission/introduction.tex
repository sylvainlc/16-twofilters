State-space models play a key role in a large variety of disciplines such as engineering, econometrics, computational biology or signal processing, see \cite{douc:moulines:stoffer:2014,doucet:defreitas:gordon:2001} and references therein. This paper provides a nonasymptotic analysis of a Sequential Monte Carlo Method (SMC) which aims at performing optimal smoothing in nonlinear and non Gaussian state space models. Given two measurable spaces $(\Xset,\sigmaX)$ and $(\Yset,\sigmaY)$, consider a bivariate stochastic process $\{(X_{t},Y_{t})\}_{t\geq 0}$ taking values in the product space $(\Xset\times\Yset,\sigmaX\otimes\sigmaY)$, where the hidden Markov state sequence $\{X_{t}\}_{t\geq 0}$ is observed only through the observation process $\{Y_{t}\}_{t\geq 0}$.
Statistical inference in general state space models usually involves the computation  of conditional distributions of some unobserved states given a set of observations. These posterior distributions are crucial to compute smoothed expectations of additive functionals which appear naturally for maximum likelihood parameter inference in hidden Markov models (computation of the Fisher score or of the intermediate quantity of the Expectation Maximization algorithm), see \cite[Chapter $10$ and $11$]{cappe:moulines:ryden:2005}, \cite{kantas:doucet:signh:2015,lecorff:fort:2013a,lecorff:fort:2013b,doucet:poyiadjis:singh:2011}.

Nevertheless, exact computation of the filtering and smoothing distributions is possible only for linear and Gaussian state spaces or when the state space $\Xset$ is finite. This paper focuses on particular  instances of Sequential Monte Carlo methods which approximate these sequences of distributions in a general state space $\Xset$ with random samples, named particles, associated with nonnegative importance weights. Those particle filters and smoothers rely on the combination of sequential importance sampling steps to propagate particles in the state space and importance resampling steps to duplicate or discard particles according to their importance weights. The first implementation of these SMC methods, introduced in \cite{gordon:salmond:smith:1993,kitagawa:1996}, propagates the particles using the Markov kernel of the hidden process $\{X_{t}\}_{t\geq 0}$ and uses a multinomial resampling step based on the importance weights to select particles at each time step. An interesting feature of this particle filter is that it also provides an approximation of the joint smoothing distribution by storing the ancestral line of each particle with a complexity growing only linearly with the number $N$ of particles, see for instance \cite{delmoral:2004}. However, this smoothing algorithm has a major shortcoming since the successive resampling steps induce  an important  depletion of the particle trajectories. This degeneracy of the particle sequences leads to trajectories sharing a common ancestor path; see \cite{jacob:murray:rubenthaler:2013,doucet:poyiadjis:singh:2011} for a discussion.


Approximations of the smoothing distributions may also be obtained using the forward filtering backward smoothing decomposition in general state space models.  The Forward Filtering Backward Smoothing algorithm (FFBS) and  the Forward Filtering Backward Simulation algorithm (FFBSi) developed respectively in \cite{doucet:godsill:andrieu:2000,huerzeler:kunsch:1998,kitagawa:1996} and \cite{godsill:doucet:west:2004} avoid the path degeneracy issue at the cost of a computational complexity growing with $N^2$. Both algorithms rely on a forward pass which produces a set of particles and weights approximating the sequence of filtering distributions up to time $T$. Then, the backward pass of the FFBS algorithm modifies all the weights computed in the forward pass according to the so-called  backward decomposition of the smoothing distribution keeping all the particles fixed. On the other hand, the FFBSi  algorithm samples independently particle trajectories among all the possible paths produced by the forward pass. It is  shown in \cite{cappe:2011,delmoral:doucet:singh:2010,mongillo:deneve:2008} that the FFBS algorithm can be implemented using only a forward pass when approximating smoothed expectations of additive functionals but with a complexity still growing quadratically with $N$.  Under the mild assumption that the transition density of the hidden chain $\{X_{t}\}_{t\geq 0}$ is uniformly bounded above, \cite{douc:garivier:moulines:olsson:2011} proposed an accept-reject mechanism to implement the FFBSi algorithm with a complexity growing only linearly with $N$. Concentration inequalities,  controls of the $\rmL_{q}$-norm of the deviation between smoothed functionals and their approximations and Central Limit Theorems (CLT) for the FFBS and the FFBSi algorithms have been established in \cite{delmoral:doucet:singh:2010,douc:garivier:moulines:olsson:2011,dubarry:lecorff:2013}.

Recently, \cite{olsson:westerborn:2015} proposed a new SMC algorithm, the particle-based rapid incremental smoother (PaRIS), to approximate online, using only a forward pass, smoothed expectations of additive functionals. The crucial feature of this algorithm is that its complexity grows only linearly with $N$ as it samples on-the-fly particles distributed according to the backward dynamics of the hidden chain conditionally on the observations $Y_0,\ldots,Y_T$.  The authors show concentration inequalities and CLT for the estimators provided by the PaRIS algorithm.

In this paper, we extend the theoretical results available for the SMC approximations of smoothing distributions to the estimators given by the two-filter algorithms. The two-filter smoothing decomposition was first given in \cite{bresler:1986} and used in \cite{kitagawa:1994} to design a Gaussian-sum smoother for non Gaussian state spaces. It was then introduced in the particle filter literature by \cite{kitagawa:1996} and developed further by \cite{briers:doucet:maskell:2010} and \cite{fearnhead:wyncoll:tawn:2010}. The two-filter approach combines the output of two independent filters, one that evolves forward in time and approximates the filtering distributions and another that evolves backward in time approximating a quantity proportional to the posterior distribution of a state given future observations.  In \cite{persing:jasra:2013}, the authors proposed an estimation of the likelihood of the observations using the algorithm of \cite{briers:doucet:maskell:2010}. They established a CLT for this unbiased estimator when the number of particles grows to $+\infty$. In \cite{fearnhead:wyncoll:tawn:2010}, the authors introduced a proposal mechanism leading to algorithms whose complexity grows linearly with the number of particles.  An algorithm similar to the algorithm of  \cite{briers:doucet:maskell:2010} may also be implemented with an $\mathcal{O}(N)$ computational complexity following the same idea. We analyze in a common framework all these algorithms which approximate the marginal smoothing distributions (smoothing distributions of one state given all the observations) and provide concentration inequalities as well as CLT. It is shown that the asymptotic variance (as $N$ goes to $+\infty$) is the sum of two contributions, one associated with each particle filter. This is of particular interest since the works of \cite{lee:whiteley:2015} and \cite{douc:olsson:2017}  introduced an algorithm to consistently estimate the asymptotic variance of particle filters using only the random samples produced within the SMC method.

This paper is organized as follows. Section~\ref{sec:TwoFilters} introduces the different particle approximations of the marginal smoothing distributions given by the two-filter algorithms. Sections~\ref{sec:ExponentialTwoFilters} and~\ref{sec:CLTTwoFilters} provide exponential deviation inequalities and CLT for the particle approximations under mild assumptions on the hidden Markov chain. Under additional {\em strong mixing assumptions}, it is shown that the results of Section~\ref{sec:ExponentialTwoFilters} are uniform in time and that the asymptotic variance in Section~\ref{sec:CLTTwoFilters} may be uniformly bounded in time. All proofs are postponed to Section~\ref{sec:proofs}.

\subsection*{Notations and conventions}
Let $\Xset$ and $\Yset$ be two general state-spaces endowed with countably generated $\sigma$-fields $\sigmaX$ and $\sigmaY$. $\functionset[b]{X}$ is the set of all real valued bounded measurable functions on $(\Xset,\sigmaX)$. $Q$ is a Markov transition kernel defined on $\Xset\times\sigmaX$ and $\{g_{t}\}_{t\geq 0}$ a family of positive functions defined on $\Xset$. For any $x \in \Xset$, $Q(x,\cdot)$ has a density $q(x, \cdot)$ with respect to a measure $\lambda$ on $(\Xset,\sigmaX)$.  The oscillation of a real valued function defined on a space $\mathsf{Z}$ is given by:
$\oscnorm{h} \eqdef \sup_{z,z'\in\mathsf{Z}}\left|h(z)-h(z')\right|$.
